{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading data and basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import fastparquet as fp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "# for jupyter notebook, this is necessary to show plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change current working directory\n",
    "default_dir = '..'\n",
    "\n",
    "if os.getcwd() != default_dir:\n",
    "    os.chdir(default_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize input directory\n",
    "input_dir = '..'\n",
    "\n",
    "# read parquet files into dataframes\n",
    "df_vitals = pd.read_parquet(input_dir + '/Vitals/')\n",
    "df_surgery = pd.read_parquet(input_dir + '/Surgery/')\n",
    "df_reanimatie = pd.read_parquet(input_dir + '/Reanimatiebeleid/')\n",
    "df_lab = pd.read_parquet(input_dir + '/Lab/')\n",
    "df_ic = pd.read_parquet(input_dir + '/IC_Opnames/')\n",
    "df_demo = pd.read_parquet(input_dir + '/Demographics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check duplicates\n",
    "# df_reanimatie.duplicated().sum()\n",
    "\n",
    "# drop duplicated rows and reset indices\n",
    "df_reanimatie = df_reanimatie.drop_duplicates().reset_index(drop=True)\n",
    "df_lab = df_lab.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy\n",
    "copy_vitals = df_vitals.copy()\n",
    "copy_surgery = df_surgery.copy()\n",
    "copy_reanimatie = df_reanimatie.copy()\n",
    "copy_lab = df_lab.copy()\n",
    "copy_ic = df_ic.copy()\n",
    "copy_demo = df_demo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "copy_vitals = copy_vitals.drop(columns = ['MetingOms', 'MetingEenheid', 'MeetOptie'])\n",
    "copy_surgery = copy_surgery.drop(columns = ['NaarAfdelingDatumTijd', 'HoofdverrichtingOms', 'PrioriteitOms'])\n",
    "copy_reanimatie = copy_reanimatie.drop(columns = ['Gekozen_beleid', 'Reanimeren', 'TmDatum'])\n",
    "copy_lab = copy_lab.drop(columns = ['BepalingCode', 'GroepOms', 'Eenheid', 'GlimsCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop duplicated rows and reset indices because dropping variables give duplicates\n",
    "# # but we'll just do this at the next section per each dataframe\n",
    "# copy_reanimatie = copy_reanimatie.drop_duplicates().reset_index(drop=True)\n",
    "# copy_lab = copy_lab.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# copy_reanimatie.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check duplicated values from copy dataframes\n",
    "# # Dropping columns introduces duplicated rows because, \n",
    "# # for example, in copy_lab, the BepalingCode was different for the same patient, or etc, \n",
    "# # and dropping those kinds of columns can introduce duplicates. \n",
    "\n",
    "# duplicates_vitals = copy_vitals[copy_vitals.duplicated()]\n",
    "# duplicates_surgery = copy_surgery[copy_surgery.duplicated()]\n",
    "# duplicates_reanimatie = copy_reanimatie[copy_reanimatie.duplicated()]\n",
    "# duplicates_lab = copy_lab[copy_lab.duplicated()]\n",
    "# duplicates_ic = copy_ic[copy_ic.duplicated()]\n",
    "# duplicates_demo = copy_demo[copy_demo.duplicated()]\n",
    "\n",
    "# duplicates_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove case sensitivity in variable names\n",
    "copy_vitals.columns = copy_vitals.columns.str.lower()\n",
    "copy_surgery.columns = copy_surgery.columns.str.lower()\n",
    "copy_reanimatie.columns = copy_reanimatie.columns.str.lower()\n",
    "copy_lab.columns = copy_lab.columns.str.lower()\n",
    "copy_ic.columns = copy_ic.columns.str.lower()\n",
    "copy_demo.columns = copy_demo.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raname variables using _\n",
    "copy_vitals = copy_vitals.rename(columns={'pid': 'p_id', \n",
    "                                  'opnameid': 'opname_id', \n",
    "                                'metingdatumtijd': 'meting_datum_tijd',       \n",
    "                                'meetwaarde1': 'meet_waarde1',  \n",
    "                                'meetwaarde2': 'meet_waarde2', \n",
    "                                'meetwaarde3': 'meet_waarde3'})\n",
    "\n",
    "copy_surgery = copy_surgery.rename(columns={'pid': 'p_id', \n",
    "                                  'opnameid': 'opname_id', \n",
    "                                'operatieid': 'operatie_id',       \n",
    "                                'ok_begindatumtijd': 'ok_begin_datum_tijd',  \n",
    "                                'ok_einddatumtijd': 'ok_eind_datum_tijd', \n",
    "                                'hoofdverrichtingcode': 'hoofdverrichting_code',\n",
    "                                'prioriteitcode': 'prioriteit_code'})\n",
    "\n",
    "copy_reanimatie = copy_reanimatie.rename(columns={'pid': 'p_id', \n",
    "                                  'opnameid': 'opname_id', \n",
    "                                'vanafdatum': 'vanaf_datum'})\n",
    "\n",
    "copy_lab = copy_lab.rename(columns={'pid': 'p_id', \n",
    "                                  'opnameid': 'opname_id', \n",
    "                                'bepalingoms': 'bepaling_oms',       \n",
    "                                'labdatumtijd': 'lab_datum_tijd'})\n",
    "\n",
    "copy_ic = copy_ic.rename(columns={'pid': 'p_id', \n",
    "                                  'opnameid': 'opname_id', \n",
    "                                'opnamedatumtijd': 'ic_opname_datum_tijd',       \n",
    "                                'ontslagdatumtijd': 'ic_ontslag_datum_tijd',  \n",
    "                                'specialismecode': 'ic_specialisme_code', \n",
    "                                'afdelingcode': 'afdelings_code'})\n",
    "\n",
    "copy_demo = copy_demo.rename(columns={'pid': 'p_id', \n",
    "                                  'opnameid': 'opname_id', \n",
    "                                'overlijdensdatum': 'overlijdens_datum',       \n",
    "                                'opnamedatumtijd': 'opname_datum_tijd',  \n",
    "                                'ontslagdatumtijd': 'ontslag_datum_tijd', \n",
    "                                'specialismecode': 'specialisme_code',\n",
    "                                'opnametypeoms': 'opname_type_oms'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if there is only date\n",
    "# copy_demo['overlijdens_datum'].dt.time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes = [copy_demo, copy_vitals, copy_surgery, copy_reanimatie, copy_lab, copy_ic]\n",
    "# merged_df = dataframes[0]\n",
    "# for df in dataframes[1:]:\n",
    "#     merged_df = pd.merge(merged_df, df, on=['p_id', 'opname_id'], how='left')\n",
    "#     del df\n",
    "\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting datetime and handling duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vitals:    \n",
    "As they (at least NIBP) were measured in Nanoseconds (e.g. 11:30:00:020, 11:30:00.010), converting 'meting_datum_tijd' to a standard datetime (rounded to seconds) creates many duplicates based on a combination of 'p_id', 'opname_id', 'meting_datum_tijd', 'meting'. datetime64 can also truncate nanoseconds, if using [s] (e.g. 16:25:26.290448 to 16:25:26 from df_demo)    \n",
    "Data loss is inevitable when handling this, as we do not consider nanoseconds in real life. An average value for MW1, MW2, and MW3 is used.    \n",
    "The same approach will be used to convert 'meting_datum_tijd' to minutes or every 10 minutes. It might be interesting to experiment with the discretization of time and its effect on a result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT USED\n",
    "# # convert meting_datum_tijd to standard datetime format with seconds\n",
    "# copy_vitals['meting_datum_tijd'] = copy_vitals['meting_datum_tijd'].values.astype('datetime64[s]')\n",
    "\n",
    "# # check converted dataframe that do not have same datetime value as original dataframe\n",
    "# copy_vitals[copy_vitals['meting_datum_tijd'] != df_vitals['MetingDatumTijd']].head()\n",
    "\n",
    "# # calculate the average value for the combination\n",
    "# copy_vitals = copy_vitals.groupby(['p_id', 'opname_id', 'meting_datum_tijd', 'meting'], as_index=False).agg({\n",
    "#     'meet_waarde1': 'mean', 'meet_waarde2': 'mean', 'meet_waarde3': 'mean'})\n",
    "\n",
    "# # drop duplicated rows\n",
    "# copy_vitals = copy_vitals.drop_duplicates().reset_index(drop=True)\n",
    "# copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check which rows are kept and dropped if assuming date time is converted\n",
    "# copy_vitals = copy_vitals.sort_values(by='meting_datum_tijd')\n",
    "# copy_vitals['temp_meting_datum_tijd'] = copy_vitals['meting_datum_tijd'].values.astype('datetime64[s]')\n",
    "# cols = ['p_id', 'opname_id', 'meting', 'temp_meting_datum_tijd']\n",
    "# condition = copy_vitals.duplicated(subset=cols, keep=False)\n",
    "# duplicates = copy_vitals[condition].copy()\n",
    "# duplicates['action'] = duplicates.duplicated(subset=cols, keep='last').map({True: 'drop', False: 'keep'})\n",
    "\n",
    "# kept_rows = duplicates[duplicates['action'] == 'keep']\n",
    "# dropped_rows = duplicates[duplicates['action'] == 'drop']\n",
    "\n",
    "# comparison = kept_rows.merge(\n",
    "#     dropped_rows,\n",
    "#     on=cols,\n",
    "#     how='inner',\n",
    "#     suffixes=('_kept', '_dropped')\n",
    "# )\n",
    "# comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Rounding up measurement time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OLD CODE\n",
    "# # assume the date time type is rounded from nanoseconds to hour, \n",
    "# # then based on the combination, only keep the recent value per time\n",
    "# copy_vitals = copy_vitals.sort_values(by='meting_datum_tijd')\n",
    "# copy_vitals['temp_meting_datum_tijd'] = copy_vitals['meting_datum_tijd'].values.astype('datetime64[h]')\n",
    "# copy_vitals = copy_vitals.drop_duplicates(subset=['p_id', 'opname_id', 'meting', 'temp_meting_datum_tijd'], keep='last')\n",
    "# copy_vitals = copy_vitals.drop(columns=['temp_meting_datum_tijd'])\n",
    "# copy_vitals['meting_datum_tijd'] = copy_vitals['meting_datum_tijd'].values.astype('datetime64[h]')\n",
    "# copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to nearest interval per parameter\n",
    "# then based on the combination, only keep the recent value per time\n",
    "# info_cols are variables that can change by time. For instance leeftijd doesn't\n",
    "def round_nearest_interval(df, datetime_cols, info_cols, N, additional_ids=[]):\n",
    "\n",
    "    p_id = 'p_id'\n",
    "    opname_id = 'opname_id'\n",
    "\n",
    "    df = df.sort_values(by=datetime_cols[0])\n",
    "    \n",
    "    # N = 0, 0.5, 1, 2\n",
    "    for datetime_col in datetime_cols:\n",
    "        df[datetime_col] = pd.to_datetime(df[datetime_col], errors='coerce')    \n",
    "        \n",
    "        # nearest minute from nanoseconds\n",
    "        if N == 0:\n",
    "            interval = 'T'\n",
    "        \n",
    "        # nearest hour or 2 hours or more\n",
    "        elif N >= 1:\n",
    "            interval = f'{int(N)}H'\n",
    "            \n",
    "        # if 0 < N < 1\n",
    "        else:\n",
    "            minutes = int(N * 60)\n",
    "            interval = f'{minutes}T'\n",
    "\n",
    "        df['temp_' + datetime_col] = df[datetime_col].dt.round(interval)\n",
    "\n",
    "    # keep only the recent measurement based on this combination\n",
    "    temp_datetime_cols = ['temp_' + col for col in datetime_cols]\n",
    "    subset_cols = [p_id, opname_id] + info_cols + temp_datetime_cols + additional_ids\n",
    "    df = df.drop_duplicates(subset=subset_cols, keep='last')\n",
    "\n",
    "    for datetime_col in datetime_cols:\n",
    "        df[datetime_col] = df['temp_' + datetime_col]\n",
    "        df = df.drop(columns=['temp_' + datetime_col])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals = round_nearest_interval(\n",
    "    df=copy_vitals,\n",
    "    datetime_cols=['meting_datum_tijd'],\n",
    "    info_cols=['meet_waarde1', 'meet_waarde2', 'meet_waarde3'],\n",
    "    N=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery = round_nearest_interval(\n",
    "    df=copy_surgery,\n",
    "    datetime_cols=['ok_begin_datum_tijd', 'ok_eind_datum_tijd'],\n",
    "    info_cols=['hoofdverrichting_code', 'prioriteit_code'],\n",
    "    N=1,\n",
    "    additional_ids=['operatie_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie = round_nearest_interval(\n",
    "    df=copy_reanimatie,\n",
    "    datetime_cols=['vanaf_datum'],\n",
    "    info_cols=['care_order'],\n",
    "    N=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lab = round_nearest_interval(\n",
    "    df=copy_lab,\n",
    "    datetime_cols=['lab_datum_tijd'],\n",
    "    info_cols=['bepaling_oms', 'uitslag'],\n",
    "    N=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic[['ic_opname_datum_tijd', 'ic_ontslag_datum_tijd']] = (\n",
    "    copy_ic[['ic_opname_datum_tijd', 'ic_ontslag_datum_tijd']].values.astype('datetime64[s]')\n",
    ")\n",
    "\n",
    "copy_ic = round_nearest_interval(\n",
    "    df=copy_ic,\n",
    "    datetime_cols=['ic_opname_datum_tijd', 'ic_ontslag_datum_tijd'],\n",
    "    info_cols=['ic_specialisme_code', 'afdelings_code'],\n",
    "    N=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo = round_nearest_interval(\n",
    "    df=copy_demo,\n",
    "    datetime_cols=['overlijdens_datum', 'opname_datum_tijd', 'ontslag_datum_tijd'],\n",
    "    info_cols=['specialisme_code', 'spoed', 'opname_type_oms'],\n",
    "    N=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT USED\n",
    "# # check original dataframe that do not have same datetime value as original dataframe\n",
    "# df_vitals[copy_vitals['meting_datum_tijd'] != df_vitals['MetingDatumTijd']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_vitals.duplicated(subset=['p_id', 'opname_id', 'meting_datum_tijd', 'meting'], keep=False)\n",
    "copy_vitals[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Surgery:   \n",
    "There are no duplicates based on the defined combination.  \n",
    "Therefore, we do not do anything extra here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date and time columns to a standard datetime format with seconds\n",
    "copy_surgery[['ok_begin_datum_tijd', 'ok_eind_datum_tijd']] = (\n",
    "    copy_surgery[['ok_begin_datum_tijd', 'ok_eind_datum_tijd']].values.astype('datetime64[s]')\n",
    ")\n",
    "    \n",
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_surgery.duplicated(subset=['p_id', 'opname_id', 'operatie_id', \n",
    "                                             'ok_begin_datum_tijd', 'ok_eind_datum_tijd'], \n",
    "                                     keep=False)\n",
    "copy_surgery[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reanimatie:   \n",
    "We drop some duplicated rows after removing other columns that are not going to be used (Gekozen_beleid, Reanimeren, TmDatum).   \n",
    "Also for other duplicated rows grouped by the defined combinations, only keep rows that have recent rows.    \n",
    "vanaf_datum == TmDatum does not give a valid care order because it means care order had been updated later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date and time column to a standard datetime format with seconds\n",
    "copy_reanimatie['vanaf_datum'] = copy_reanimatie['vanaf_datum'].values.astype('datetime64[s]')\n",
    "\n",
    "# check the first occurence of the duplicates based on the combination\n",
    "first_duplicates = copy_reanimatie.duplicated(subset=['p_id', 'opname_id', 'vanaf_datum'], keep='first')\n",
    "copy_reanimatie[first_duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # check if there are any rows that have different vanaf_datum before converting and after converting\n",
    "# # # there are not. Therefore the duplicates above occured likely due to other columns (Gekozen_beleid, Reanimeren, TmDatum) then. \n",
    "# df_reanimatie[copy_reanimatie['vanaf_datum'] != df_reanimatie['VanafDatum']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_reanimatie.duplicated(subset=['p_id', 'opname_id', 'vanaf_datum'], keep=False)\n",
    "copy_reanimatie[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first duplicated row\n",
    "duplicate0 = copy_reanimatie[duplicates].iloc[0]\n",
    "\n",
    "# store the first duplicated row's p_id and opname_id\n",
    "p_id0 = duplicate0['p_id']\n",
    "opname_id0 = duplicate0['opname_id']\n",
    "\n",
    "# show the original data of the patient from the duplicated row\n",
    "# vanaf_datum is same and only keep the top row (latest decision)\n",
    "# as if vanaf_datum and TmDatum (end date) are the same, \n",
    "# this means care order has been changed afterwards\n",
    "original0 = df_reanimatie[(df_reanimatie['PID'] == p_id0) & (df_reanimatie['OpnameID'] == opname_id0)]\n",
    "original0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the third duplicated row\n",
    "duplicate2 = copy_reanimatie[duplicates].iloc[2]\n",
    "\n",
    "# store the third duplicated row's p_id and opname_id\n",
    "p_id2 = duplicate2['p_id']\n",
    "opname_id2 = duplicate2['opname_id']\n",
    "\n",
    "# show the original data of the patient from the duplicated row\n",
    "original2 = df_reanimatie[(df_reanimatie['PID'] == p_id2) & (df_reanimatie['OpnameID'] == opname_id2)]\n",
    "original2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie = copy_reanimatie[~first_duplicates].reset_index(drop=True)\n",
    "copy_reanimatie.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if only the first occurence indeed keeps intact\n",
    "copy_reanimatie[(copy_reanimatie['p_id'] == p_id0) & (copy_reanimatie['opname_id'] == opname_id0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lab:   \n",
    "Similar to Reanimatie dataframe, duplicates happened due to other unused columns. Therefore we would calculate the average values for uitslag for the given lab_datum_tijd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date and time column to a standard datetime format with seconds\n",
    "copy_lab['lab_datum_tijd'] = copy_lab['lab_datum_tijd'].values.astype('datetime64[s]')\n",
    "\n",
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_lab.duplicated(subset=['p_id', 'opname_id', 'bepaling_oms', 'lab_datum_tijd'], keep=False)\n",
    "copy_lab[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check original dataframe that do not have same datetime value as original dataframe\n",
    "# # there are no duplicates. The duplicates exist also likely due to other columns \n",
    "# df_lab[copy_lab['lab_datum_tijd'] != df_lab['Labdatumtijd']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT USED\n",
    "# # calculate the average value for the combination\n",
    "# copy_lab = copy_lab.groupby(['p_id', 'opname_id', 'bepaling_oms', 'lab_datum_tijd'], \n",
    "#                             as_index=False).agg({'uitslag': 'mean'})\n",
    "\n",
    "# # drop duplicated rows\n",
    "# copy_lab = copy_lab.drop_duplicates().reset_index(drop=True)\n",
    "# copy_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter non-numeric values for uitslag\n",
    "copy_lab['uitslag'] = pd.to_numeric(copy_lab['uitslag'], errors='coerce')\n",
    "\n",
    "# same as 'meting_datum_tijd' in vitals. \n",
    "# assume converted datetime and only keep the recent one based on the combination\n",
    "copy_lab = copy_lab.sort_values(by='lab_datum_tijd')\n",
    "copy_lab['temp_lab_datum_tijd'] = copy_lab['lab_datum_tijd'].values.astype('datetime64[s]')\n",
    "copy_lab = copy_lab.drop_duplicates(\n",
    "    subset=['p_id', 'opname_id', 'bepaling_oms', 'temp_lab_datum_tijd'],\n",
    "    keep='last'\n",
    ")\n",
    "copy_lab = copy_lab.drop(columns=['temp_lab_datum_tijd'])\n",
    "copy_lab['lab_datum_tijd'] = copy_lab['lab_datum_tijd'].values.astype('datetime64[s]')\n",
    "copy_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_lab.duplicated(subset=['p_id', 'opname_id', 'bepaling_oms', 'lab_datum_tijd'], keep=False)\n",
    "copy_lab[duplicates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IC_Opnames:   \n",
    "Same as Surgery dataframe, there are no duplicates based on the defined combination.  \n",
    "Therefore, we do not do anything extra here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_ic.duplicated(subset=['p_id', 'opname_id', \n",
    "                                        'ic_opname_datum_tijd', 'ic_ontslag_datum_tijd'], keep=False)\n",
    "copy_ic[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic = copy_ic.drop_duplicates(\n",
    "    subset=['p_id', 'opname_id', 'ic_opname_datum_tijd', 'ic_ontslag_datum_tijd', 'ic_specialisme_code'],\n",
    "    keep='last'\n",
    ")\n",
    "\n",
    "copy_ic[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Demographics:   \n",
    "Same as Surgery dataframe, there are no duplicates based on the defined combination.  \n",
    "Therefore, we do not do anything extra here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date and time column to a standard datetime format with seconds\n",
    "copy_demo['overlijdens_datum'] = pd.to_datetime(copy_demo['overlijdens_datum'])\n",
    "copy_demo['opname_datum_tijd'] = pd.to_datetime(copy_demo['opname_datum_tijd'])\n",
    "copy_demo['ontslag_datum_tijd'] = pd.to_datetime(copy_demo['ontslag_datum_tijd'])\n",
    "\n",
    "copy_demo[['overlijdens_datum', 'opname_datum_tijd', 'ontslag_datum_tijd']] = (\n",
    "    copy_demo[['overlijdens_datum', 'opname_datum_tijd', 'ontslag_datum_tijd']].values.astype('datetime64[s]')\n",
    ")\n",
    "    \n",
    "# check if there are duplicated rows based on the combination\n",
    "duplicates = copy_demo.duplicated(subset=['p_id', 'opname_id', 'geslacht', \n",
    "                                          'leeftijd', 'overlijdens_datum', \n",
    "                                          'opname_datum_tijd', 'ontslag_datum_tijd'], \n",
    "                                  keep=False)\n",
    "copy_demo[duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check duplicates rows overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check any remaining duplicated rows\n",
    "duplicates_vitals = copy_vitals[copy_vitals.duplicated()]\n",
    "duplicates_surgery = copy_surgery[copy_surgery.duplicated()]\n",
    "duplicates_reanimatie = copy_reanimatie[copy_reanimatie.duplicated()]\n",
    "duplicates_lab = copy_lab[copy_lab.duplicated()]\n",
    "duplicates_ic = copy_ic[copy_ic.duplicated()]\n",
    "duplicates_demo = copy_demo[copy_demo.duplicated()]\n",
    "\n",
    "duplicates_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_reanimatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering and handling missing datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition = copy_demo['opname_datum_tijd'] > copy_demo['ontslag_datum_tijd']\n",
    "# copy_demo[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where Ontslag occurs before Opname\n",
    "condition = copy_demo['opname_datum_tijd'] > copy_demo['ontslag_datum_tijd']\n",
    "copy_demo = copy_demo[~condition].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in dates\n",
    "print(copy_vitals['meting_datum_tijd'].isna().sum())\n",
    "print(copy_surgery[['ok_begin_datum_tijd', 'ok_eind_datum_tijd']].isna().sum())\n",
    "print(copy_reanimatie['vanaf_datum'].isna().sum())\n",
    "print(copy_lab['lab_datum_tijd'].isna().sum())\n",
    "print(copy_ic[['ic_opname_datum_tijd', 'ic_ontslag_datum_tijd']].isna().sum())\n",
    "print(copy_demo[['overlijdens_datum', 'opname_datum_tijd', 'ontslag_datum_tijd']].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Handling missing values from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check where the ontslag_datum_tijd is missing\n",
    "copy_demo[copy_demo['ontslag_datum_tijd'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the case where OntslagDatum missing as we cannot assume 'time' but only 'date' from Overlijdens'Datum'\n",
    "# also this ontslag_datum_tijd is missing possibly due to extracting data around that time\n",
    "copy_demo = copy_demo[copy_demo['ontslag_datum_tijd'].notna()].reset_index(drop=True)\n",
    "copy_demo[copy_demo['ontslag_datum_tijd'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlijdens_datum: we have to assume patients are alive when this variable is missing. \n",
    "# leave them as they are. Some models can accept NaN values\n",
    "\n",
    "# TODO for future -> Do it in cleaning_v2: \n",
    "# however, we could create an extra column that indicates alive or not alive (this is an event)\n",
    "# mark True if they're alive within 12 hours?? because that's the focus? \n",
    "# but from which 'event' 12 hours? from admission (opname)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok_eind_datum_tijd. \n",
    "# check if OntslagDatum exists then for missing Einddatum values based on copy_demo\n",
    "# What should I do with this? Fill ontslag_datum_tijd with einddatumtijd?? or leave as they are now?\n",
    "# Were there even surgerys with these patients? \n",
    "# Would drop the rows because rows with missing ok_eind_datum_tijd not gonna be defined as a valid episode / event. \n",
    "# (because you need start time and end time)\n",
    "# surgery wasn't performed probably. but still have to ask ashely.\n",
    "# see below\n",
    "\n",
    "merged_df = copy_demo.merge(\n",
    "    copy_surgery[['p_id', 'opname_id', 'ok_eind_datum_tijd', 'ok_begin_datum_tijd']],\n",
    "    on = ['p_id', 'opname_id'],\n",
    "    how = 'left'\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# patients where surgery einddatum missing\n",
    "filtered_df = merged_df[merged_df['ok_eind_datum_tijd'].isna()]\n",
    "\n",
    "# patients where surgery einddatum missing\n",
    "filtered_df.head()\n",
    "\n",
    "# count numbers: 0 \n",
    "# people who have missing ok_eind_datum_tijd have ontslag_datum_tijd\n",
    "num = filtered_df['ontslag_datum_tijd'].isna().sum()\n",
    "print(f\"Numbers of patients whose einddatumtijd don't exist, as well as ontslagdatumtijd: {num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people who have missing ok_eind_datum_tijd have ontslag_datum_tijd\n",
    "filtered_df[filtered_df['ontslag_datum_tijd'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot assume exact datetime\n",
    "# But I think we could keep this for defining an event,\n",
    "# if our focus in on the ontslag_datum_tijd instead of ok_eind_datum_tijd\n",
    "\n",
    "# no, we just remove these.\n",
    "# This should generally not happen but it might happen\n",
    "# if there are some smaller surgery that are performed in holding or in the recovery.\n",
    "copy_surgery = copy_surgery[copy_surgery['ok_eind_datum_tijd'].notna()].reset_index(drop=True)\n",
    "copy_surgery[copy_surgery['ok_eind_datum_tijd'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why the date time starts at 00:00:00 a lot? (both opname datum tijd_ic, ontslag ic)\n",
    "# somehow the rows were created separately and should find a continous time per p_id, opname_id, and smth smth \n",
    "# ic_opnames has many separate rows for patients, surgery.. opnamedatum tijd etc \n",
    "# Look the note 1-1\n",
    "# reason: this is because of finance. A new IC admissions starts then because of billing hours\n",
    "\n",
    "# when do they change patient's afdelings code? what does that mean?\n",
    "# and why do they split times for the same afdelings code too? \n",
    "# should I find a continous time for both cases? \n",
    "# (either drop afdelings code and merge rows, or only merge rows for the same afdelings code)\n",
    "\n",
    "# this is for handling rows that have split time due to billing hours\n",
    "non_split_ic = copy_ic[~copy_ic.duplicated(subset=['p_id', 'opname_id', 'ic_specialisme_code', 'afdelings_code'], keep=False)]\n",
    "\n",
    "split_ic = copy_ic.sort_values(by=['p_id', 'opname_id', 'ic_specialisme_code', 'afdelings_code'])\n",
    "split_ic = split_ic[split_ic.duplicated(subset=['p_id', 'opname_id', 'ic_specialisme_code', 'afdelings_code'], keep=False)]\n",
    "split_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ic_opname_datum_tijd to earliest time, ic_ontslag_datum_tijd to latest time for each duplicated group\n",
    "# leave index as p_id, opname_id, ic_specialisme_code, afdelings_code\n",
    "# if we aren't interested in afdelings_code anymore, then set index with 3 cols only (w/o afdelings_code)\n",
    "# we can keep it\n",
    "aggregated_ic = split_ic.groupby(['p_id', 'opname_id', 'ic_specialisme_code', 'afdelings_code']).agg({\n",
    "    'ic_opname_datum_tijd': 'min', 'ic_ontslag_datum_tijd': 'max'}).reset_index()\n",
    "\n",
    "copy_ic = pd.concat([non_split_ic, aggregated_ic]).reset_index(drop=True)\n",
    "copy_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic['ic_opname_datum_tijd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic['ic_ontslag_datum_tijd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if there are still duplicated rows based on the combination\n",
    "duplicates = copy_ic.sort_values(by=['p_id', 'opname_id', 'ic_specialisme_code', 'afdelings_code'])\n",
    "duplicates = duplicates[duplicates.duplicated(subset=['p_id', 'opname_id', 'ic_specialisme_code', 'afdelings_code'], keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Filtering and cleaning other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether columns with float type are indeed float or integer\n",
    "cols = ['meet_waarde1', 'meet_waarde2', 'meet_waarde3']\n",
    "\n",
    "def is_actually_int(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, float):\n",
    "        return x.is_integer()\n",
    "    return False\n",
    "\n",
    "applied = copy_vitals[cols].applymap(is_actually_int)\n",
    "copy_vitals['integers'] = applied.all(axis=1, skipna=True)\n",
    "rows_integers = copy_vitals[copy_vitals['integers']]\n",
    "rows_floats = copy_vitals[~copy_vitals['integers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_integers['meting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_floats['meting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_floats[rows_floats['meting']=='AVPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals[(copy_vitals['meting'] == 'Temp')]['meet_waarde1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check any rows that have missing values to calculate the meet_waarde3 values for NIBP meting\n",
    "copy_vitals[(copy_vitals['meting'] == 'NIBP') & (copy_vitals.isna().any(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing meet_waarde3 values for NIBP where both MW1 and MW2 are not missing \n",
    "# MAP = DP + 1/3(SP – DP)\n",
    "condition = (\n",
    "    (copy_vitals['meting'] == 'NIBP') &\n",
    "    copy_vitals['meet_waarde1'].notna() &\n",
    "    copy_vitals['meet_waarde2'].notna()\n",
    ")\n",
    "\n",
    "copy_vitals.loc[condition, 'meet_waarde3'] = (\n",
    "    copy_vitals.loc[condition, 'meet_waarde2'] +\n",
    "    (copy_vitals.loc[condition, 'meet_waarde1'] - copy_vitals.loc[condition, 'meet_waarde2']) / 3\n",
    ")\n",
    "\n",
    "copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows whose 'meet_waarde1' is missing for other meting that are NOT NIBP\n",
    "condition2 = (\n",
    "    (copy_vitals['meting'] != 'NIBP') &\n",
    "    (copy_vitals['meet_waarde1'].isna())\n",
    ")\n",
    "\n",
    "copy_vitals = copy_vitals[~condition2].drop_duplicates(keep='last').reset_index(drop=True)\n",
    "copy_vitals[copy_vitals['meet_waarde1'].isna()]\n",
    "# copy_vitals[copy_vitals['meting']=='HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows whose 'meet_waarde1' or 'meet_waarde2' or both are missing, for 'NIBP'\n",
    "# because 'NIBP' should have at least those two values.\n",
    "\n",
    "condition3 = (\n",
    "    (copy_vitals['meting'] == 'NIBP') & \n",
    "    (copy_vitals['meet_waarde1'].isna() | copy_vitals['meet_waarde2'].isna())\n",
    ")\n",
    "\n",
    "copy_vitals = copy_vitals[~condition3].drop_duplicates(keep='last').reset_index(drop=True)\n",
    "\n",
    "# check if there are still rows that have missing values\n",
    "copy_vitals[(\n",
    "    (copy_vitals['meting'] == 'NIBP') & \n",
    "    (copy_vitals['meet_waarde1'].isna() | copy_vitals['meet_waarde2'].isna())\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just check the values of AVPU\n",
    "copy_vitals[copy_vitals['meting']=='AVPU']['meet_waarde1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter each meting, except for AVPU (categorical) and O2 (don't need). \n",
    "# exclude EMV value\n",
    "condition4 = (\n",
    "    ((copy_vitals['meting'] == 'NIBP') & \n",
    "     (copy_vitals['meet_waarde1'] > 0) & (copy_vitals['meet_waarde1'] < 400) &\n",
    "     (copy_vitals['meet_waarde2'] > 0) & (copy_vitals['meet_waarde2'] < 400) &\n",
    "     (copy_vitals['meet_waarde3'] > 0) & (copy_vitals['meet_waarde3'] < 400)) |\n",
    "    \n",
    "    ((copy_vitals['meting'] == 'HR') & \n",
    "     (copy_vitals['meet_waarde1'] >= 0) & (copy_vitals['meet_waarde1'] < 300)) |\n",
    "    \n",
    "    ((copy_vitals['meting'] == 'Temp') & \n",
    "     (copy_vitals['meet_waarde1'] >= 29) & (copy_vitals['meet_waarde1'] <= 43)) |\n",
    "    \n",
    "    ((copy_vitals['meting'] == 'Resp') & \n",
    "     (copy_vitals['meet_waarde1'] >= 0) & (copy_vitals['meet_waarde1'] < 60)) |\n",
    "    \n",
    "    ((copy_vitals['meting'] == 'SpO2') & \n",
    "     (copy_vitals['meet_waarde1'] > 50)) |\n",
    "    \n",
    "    (copy_vitals['meting'] == 'O2') | \n",
    "    \n",
    "    (copy_vitals['meting'] == 'AVPU')\n",
    ")\n",
    "\n",
    "copy_vitals = copy_vitals[condition4].reset_index(drop=True)\n",
    "copy_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if rows with O2 are still included\n",
    "copy_vitals[copy_vitals['meting'] == 'O2'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that have no alphabets in the hoofdverreichting_code, as we cannot assume them\n",
    "unique_codes = copy_surgery['hoofdverrichting_code'].unique().tolist()\n",
    "diff_codes = [code for code in unique_codes if len(code) != len(unique_codes[0])]\n",
    "copy_surgery = copy_surgery[~copy_surgery['hoofdverrichting_code'].isin(diff_codes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a nieuw column for prioriteit code that has less categories\n",
    "def convert_prioriteit(code):\n",
    "    if code in ['E', 'B', 'SE', 'SW']:\n",
    "        return 'Elective'\n",
    "    elif code in ['S', 'SA', 'A']:\n",
    "        return 'Acute'\n",
    "    elif code == 'O':\n",
    "        return 'Unknown'\n",
    "\n",
    "copy_surgery['prioriteit'] = copy_surgery['prioriteit_code'].apply(convert_prioriteit)\n",
    "copy_surgery['prioriteit'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reanimatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing to do\n",
    "copy_reanimatie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out text values\n",
    "copy_lab['uitslag'] = pd.to_numeric(copy_lab['uitslag'], errors='coerce')\n",
    "copy_lab = copy_lab.dropna(subset=['uitslag'])\n",
    "\n",
    "# we do not need to convert the type as integer as there are indeed float values\n",
    "# copy_lab['uitslag'] = copy_lab['uitslag'].round()\n",
    "# copy_lab['uitslag'] = copy_lab['uitslag'].astype('Int64')\n",
    "\n",
    "# drop duplicated rows\n",
    "copy_lab = copy_lab.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(copy_lab['uitslag'].isna().sum())\n",
    "print(copy_lab['uitslag'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if some of values are indeed float\n",
    "is_integer = copy_lab['uitslag'] % 1 == 0\n",
    "print(copy_lab['uitslag'][~is_integer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## IC_Opnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing to do\n",
    "copy_ic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "copy_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading and trailing spaces\n",
    "def remove_spaces(df):\n",
    "    for col in df.select_dtypes(include=[object]):\n",
    "        df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "copy_demo = remove_spaces(copy_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a new column for specialisemecode + spoed\n",
    "# copy_demo['specialisme_spoed'] = copy_demo['specialisme_code'] + \"_\" + copy_demo['spoed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace space with _ only for columns with object type\n",
    "def replace_spaces(df):\n",
    "    for col in df.select_dtypes(include=[object]):\n",
    "        df[col] = df[col].apply(lambda x: x.replace(\" \", \"_\") if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "copy_reanimatie = replace_spaces(copy_reanimatie)\n",
    "copy_demo = replace_spaces(copy_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check if there are duplicated rows just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check duplicated values from copy dataframes just in case\n",
    "duplicates_vitals = copy_vitals[copy_vitals.duplicated()]\n",
    "duplicates_surgery = copy_surgery[copy_surgery.duplicated()]\n",
    "duplicates_reanimatie = copy_reanimatie[copy_reanimatie.duplicated()]\n",
    "duplicates_lab = copy_lab[copy_lab.duplicated()]\n",
    "duplicates_ic = copy_ic[copy_ic.duplicated()]\n",
    "duplicates_demo = copy_demo[copy_demo.duplicated()]\n",
    "\n",
    "duplicates_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_reanimatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reorganizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Vitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The original Vitals dataframe has 'meting' consisted of multiple different types of values (HR, NIBP, etc), and some of them have 3 values per measurement time, while some of them have 1 value per measurement time.   \n",
    "Therefore, we would prefer to have a column that have the same types/data-ish illustrated like below    \n",
    "\n",
    "* Possible cons of the reorganized dataframe:    \n",
    "1. More missing values (but we don't know how it'll do as a consequence)    \n",
    "2. More columns (For EMM, it doesn't matter)\n",
    "\n",
    "Oh but reshaping dataframe and dropped unnecessary columns actually made the dataframe way less sparse with missing values, which I think it's good.    \n",
    "Also not many more columns are created    \n",
    "\n",
    "======    \n",
    "This is necessary to reduce overheads when merging/joining, so that it has less rows that grow exponentially    \n",
    "Also to reduce memory usage     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_vitals.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing dataframe vitals. must increase RAM >= 32 (at least)\n",
    "\n",
    "# unpivot a dataframe from wide to long format, \n",
    "# with identifier variables (id_vars) remained as they are \n",
    "# and non-identifier variables (var_name, value_name) will be changed\n",
    "# waarde_type (the name of the original column) and waarde (the value in that column)\n",
    "copy_vitals = copy_vitals.melt(id_vars=['p_id', 'opname_id', 'meting_datum_tijd', 'meting'], \n",
    "                             var_name='waarde_type', value_name='waarde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the name of meting and its value (MW1, MW2, MW3)\n",
    "copy_vitals['nieuwe_waarde'] = copy_vitals['meting'] + \"_\" + copy_vitals['waarde_type']\n",
    "copy_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check why _intergers columns were created\n",
    "# p = copy_vitals['p_id'].iloc[-1]\n",
    "# df_vitals[df_vitals['PID']==p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot a dataframe from long to wide format, using the new column and original values\n",
    "copy_vitals = copy_vitals.drop(['meting', 'waarde_type'], axis=1)\n",
    "\n",
    "copy_vitals = copy_vitals.pivot_table(\n",
    "    index=['p_id', 'opname_id', 'meting_datum_tijd'],\n",
    "    columns='nieuwe_waarde',\n",
    "    values='waarde',\n",
    "    aggfunc='last'\n",
    ").reset_index()\n",
    "\n",
    "copy_vitals.columns.name = None\n",
    "\n",
    "copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dtypes back to float64 other than exceptions\n",
    "exceptions = ['p_id', 'opname_id', 'meting_datum_tijd']\n",
    "for column in copy_vitals.columns:\n",
    "    if column not in exceptions:\n",
    "        copy_vitals[column] = pd.to_numeric(copy_vitals[column], errors='coerce').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that end with _integers, this occured most likely due to NaN values\n",
    "copy_vitals = copy_vitals.loc[:, ~copy_vitals.columns.str.endswith('_integers')]\n",
    "copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns if they only contain na values\n",
    "copy_vitals = copy_vitals.dropna(axis=1, how='all')\n",
    "copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less cells than copy_vitals, seems good\n",
    "copy_vitals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_vitals.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only the first 3 characters and drop the original column\n",
    "copy_surgery['hoofdverrichting_code'] = copy_surgery['hoofdverrichting_code'].str[:3]\n",
    "copy_surgery['hoofdverrichting_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the exception \n",
    "copy_surgery['hoofdverrichting_code'] = copy_surgery['hoofdverrichting_code'].replace('BM0', 'BM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_surgery.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_surgery[\"hoofdverrichting_code_1\"] = copy_surgery[\"hoofdverrichting_code\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the best\n",
    "# copy_surgery[\"hoofdverrichting_code_2\"] = copy_surgery[\"hoofdverrichting_code\"].astype(\"category\")\n",
    "# copy_surgery[\"hoofdverrichting_code_2\"] = copy_surgery[\"hoofdverrichting_code_2\"].cat.codes.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes, uniques = pd.factorize(copy_surgery[\"hoofdverrichting_code\"])\n",
    "# copy_surgery[\"hoofdverrichting_code_3\"] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery[\"hoofdverrichting_code1\"] = copy_surgery[\"hoofdverrichting_code\"].astype(\"category\")\n",
    "print(copy_surgery[\"hoofdverrichting_code1\"].cat.categories)\n",
    "copy_surgery[\"hoofdverrichting_code1\"] = copy_surgery[\"hoofdverrichting_code1\"].cat.codes.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "# DO NOT use dtype=bool as a merge function will convert the dtype into object which is expensive\n",
    "# DO use 'boolean'\n",
    "# USE this for cleaning the data and remove them later\n",
    "def create_dummies(df, columns, prefix=None):\n",
    "    \n",
    "    # if it's a single column, convert it to a list\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    # otherwise process each column to create dummy variables\n",
    "    for column in columns:\n",
    "        \n",
    "        # check if prefix is provided, otherwise use column name\n",
    "        col_prefix = prefix if prefix else column\n",
    "        \n",
    "        # create dummy variables\n",
    "        dummies = pd.get_dummies(df[column], prefix=col_prefix, dtype='boolean')\n",
    "        \n",
    "        # concatenate the original dataframe with the new dataframe\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        \n",
    "#         # drop the original column\n",
    "#         df = df.drop(columns=[column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates too many \n",
    "copy_surgery = create_dummies(copy_surgery, 'hoofdverrichting_code')\n",
    "copy_surgery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery[\"prioriteit1\"] = copy_surgery[\"prioriteit\"].astype(\"category\")\n",
    "print(copy_surgery[\"prioriteit1\"].cat.categories)\n",
    "copy_surgery[\"prioriteit1\"] = copy_surgery[\"prioriteit1\"].cat.codes.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # make the prioriteit_code and _nieuw as boolean column\n",
    "# # dummies = pd.get_dummies(copy_surgery['prioriteit_code'], prefix='prioriteit_code', dtype='boolean')\n",
    "# # copy_surgery = pd.concat([copy_surgery, dummies], axis=1)\n",
    "# # copy_surgery = copy_surgery.drop(columns=['prioriteit_code'])\n",
    "\n",
    "# remove either one of the codes here, depends on which one we use\n",
    "copy_surgery = copy_surgery.drop(columns=['prioriteit_code'])\n",
    "\n",
    "# rename these to _code \n",
    "copy_surgery = create_dummies(copy_surgery, 'prioriteit', 'prioriteit_code')\n",
    "copy_surgery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reanimatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_reanimatie.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make the care_order as boolean column\n",
    "copy_reanimatie = create_dummies(copy_reanimatie, 'care_order')\n",
    "copy_reanimatie.head()\n",
    "\n",
    "copy_reanimatie[\"care_order1\"] = copy_reanimatie[\"care_order\"].astype(\"category\")\n",
    "print(copy_reanimatie[\"care_order1\"].cat.categories)\n",
    "copy_reanimatie[\"care_order1\"] = copy_reanimatie[\"care_order1\"].cat.codes.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_reanimatie.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing space with _ from text values (column wise)\n",
    "copy_lab['bepaling_oms'] = copy_lab['bepaling_oms'].str.strip()\n",
    "copy_lab['bepaling_oms'] = copy_lab['bepaling_oms'].str.replace(\" \", \"_\")\n",
    "copy_lab['bepaling_oms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_lab.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing lab dataframe such that it can have each bepaling column with each value\n",
    "copy_lab = copy_lab.pivot(index=['p_id', 'opname_id', 'lab_datum_tijd'], \n",
    "                                  columns='bepaling_oms', values='uitslag').reset_index()\n",
    "copy_lab.columns.name = None\n",
    "copy_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lab.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_lab.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IC_Opnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_ic.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: I'm not using these vars, so it's fine to keep it like this\n",
    "# make the ic_specialisme_code and afdelings_code as boolean column\n",
    "copy_ic = create_dummies(copy_ic, ['ic_specialisme_code', 'afdelings_code'])\n",
    "copy_ic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_ic.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_demo.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo = create_dummies(copy_demo, ['geslacht', 'spoed', 'specialisme_code', 'opname_type_oms'])\n",
    "copy_demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# drop boolean columns where there are only 2 values\n",
    "copy_demo = copy_demo.drop(['geslacht_V', 'spoed_N'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['specialisme_code1'] = copy_demo['specialisme_code'].astype(\"category\")\n",
    "print(copy_demo['specialisme_code1'].cat.categories)\n",
    "copy_demo['specialisme_code1'] = copy_demo['specialisme_code1'].cat.codes.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = copy_demo.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "print(f\"Total memory usage: {memory} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating a deterioration event and time to first event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event 1: where the death occurs when a full resuscitation code is in effect.\n",
    "# if care_order_full_code missing, handle them as False\n",
    "\n",
    "# time-to-event: copy_demo's ontslag datum tijd - 12 hours (instead of overlijdens_datum)\n",
    "merged_temp = copy_demo.merge(copy_reanimatie[['opname_id', 'p_id', 'care_order_full_code']],\n",
    "                            on=['opname_id', 'p_id'], \n",
    "                            how='left')\n",
    "\n",
    "merged_temp['care_order_full_code'] = merged_temp['care_order_full_code'].fillna(False)\n",
    "merged_temp['death_fullcode'] = merged_temp['overlijdens_datum'].notna() & merged_temp['care_order_full_code'].fillna(False)\n",
    "copy_demo['death_fullcode'] = merged_temp['death_fullcode']\n",
    "\n",
    "merged_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['death_fullcode'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event 2: where the death occurs in the ICU\n",
    "# if overlidens_datum exists and ic_ontslag_datum is same as ontslag_datum_tijd, then the patient died at IC\n",
    "# time-to-event: ic_ontslag_datum_tijd - 12 hours\n",
    "\n",
    "merged_temp = merged_temp.merge(copy_ic[['opname_id', 'p_id', 'ic_ontslag_datum_tijd']],\n",
    "                            on=['opname_id', 'p_id'], \n",
    "                            how='left')\n",
    "\n",
    "merged_temp['death_ic'] = (merged_temp['overlijdens_datum'].notna() & \n",
    "                            (merged_temp['ic_ontslag_datum_tijd'] == merged_temp['ontslag_datum_tijd']))\n",
    "\n",
    "copy_demo['death_ic'] = merged_temp['death_ic']\n",
    "copy_demo['death_ic'] = copy_demo['death_ic'].fillna(False)\n",
    "\n",
    "merged_temp[merged_temp['death_ic']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['death_ic'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event 3: ICU admission when the ICU stay is 6 hours or longer\n",
    "# but almost 80 percent is True\n",
    "# time-to-event: ic_opname_datum_tijd - 12 hours\n",
    "\n",
    "copy_ic['ic_6hr'] = (copy_ic['ic_ontslag_datum_tijd'] - copy_ic['ic_opname_datum_tijd'] >= pd.Timedelta(hours=6))\n",
    "\n",
    "copy_ic[copy_ic['ic_6hr']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic['ic_6hr'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event 4: acute surgery, if followed by ICU admission\n",
    "# time-to-event: ok_begin_datum_tijd - 12 hours\n",
    "\n",
    "copy_ic1 = copy_ic[['p_id', 'opname_id', 'ic_opname_datum_tijd', 'ic_6hr']]\n",
    "copy_surgery1 = copy_surgery[['p_id', 'opname_id', 'ok_eind_datum_tijd', 'prioriteit_code_Acute']]\n",
    "\n",
    "merged_temp1 = pd.merge(copy_ic1, copy_surgery1, on=['p_id', 'opname_id'], how='inner')\n",
    "\n",
    "merged_temp1['time_diff'] = merged_temp1['ic_opname_datum_tijd'] - merged_temp1['ok_eind_datum_tijd']\n",
    "\n",
    "merged_temp1['acute_ic'] = (\n",
    "    (merged_temp1['time_diff'] >= pd.Timedelta(0)) &\n",
    "    (merged_temp1['time_diff'] <= pd.Timedelta(hours=1)) &\n",
    "    (merged_temp1['prioriteit_code_Acute'] == True)\n",
    ")\n",
    "\n",
    "merged_temp1 = merged_temp1.drop('time_diff', axis=1)\n",
    "\n",
    "copy_demo['acute_ic'] = merged_temp1['acute_ic']\n",
    "copy_demo['acute_ic'] = copy_demo['acute_ic'].fillna(False)\n",
    "\n",
    "copy_demo[copy_demo['acute_ic']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframe that are only necessary to calculate the time-to-event\n",
    "merged_temp2 = pd.merge(merged_temp, merged_temp1, on=['p_id', 'opname_id'], how='inner')\n",
    "merged_temp2['death_ic'] = merged_temp2['death_ic'].astype('boolean')\n",
    "merged_temp2['ic_6hr'] = merged_temp2['ic_6hr'].astype('boolean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_temp2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_to_first_event(row):\n",
    "    events = []\n",
    "    if row['death_fullcode'] and pd.notna(row['ontslag_datum_tijd']):\n",
    "        events.append(('death_fullcode', row['ontslag_datum_tijd']))\n",
    "        \n",
    "    if row['death_ic'] and pd.notna(row['ic_ontslag_datum_tijd']):\n",
    "        events.append(('death_ic', row['ic_ontslag_datum_tijd']))\n",
    "        \n",
    "    if row['ic_6hr'] and pd.notna(row['ic_opname_datum_tijd']):\n",
    "        events.append(('ic_6hr', row['ic_opname_datum_tijd']))\n",
    "        \n",
    "    if row['acute_ic'] and pd.notna(row['ok_eind_datum_tijd']) and pd.notna(row['ic_opname_datum_tijd']):\n",
    "        events.append(('acute_ic', row['ok_eind_datum_tijd']))\n",
    "\n",
    "    # if no 4 events, then return observation time, False for boolean vars, 0 as event type\n",
    "    if not events:\n",
    "        no_event_time = row['ontslag_datum_tijd'] - row['opname_datum_tijd']\n",
    "        return (no_event_time, False, False, False, False, 0, False)\n",
    "    \n",
    "    earliest_event = min(events, key=lambda x: x[1])\n",
    "    \n",
    "    time_to_first_event = earliest_event[1] - row['opname_datum_tijd'] - pd.Timedelta(hours=12)\n",
    "\n",
    "    death_fullcode_first = earliest_event[0] == 'death_fullcode'\n",
    "    death_ic_first = earliest_event[0] == 'death_ic'\n",
    "    ic_6hr_first = earliest_event[0] == 'ic_6hr'\n",
    "    acute_ic_first = earliest_event[0] == 'acute_ic'\n",
    "\n",
    "    event_type = 0\n",
    "    if death_fullcode_first:\n",
    "        first_event = 1\n",
    "    elif death_ic_first:\n",
    "        first_event = 2\n",
    "    elif ic_6hr_first:\n",
    "        first_event = 3\n",
    "    elif acute_ic_first:\n",
    "        first_event = 4\n",
    "        \n",
    "    # adding a target variable if not 0 type (if one of four events happened)\n",
    "    is_first = first_event != 0\n",
    "\n",
    "    return (time_to_first_event, death_fullcode_first, death_ic_first, ic_6hr_first, acute_ic_first, first_event, is_first)\n",
    "\n",
    "result = merged_temp2.apply(get_time_to_first_event, axis=1)\n",
    "\n",
    "merged_temp2['time_to_first_event'] = result.apply(lambda x: x[0])\n",
    "merged_temp2['death_fullcode_first'] = result.apply(lambda x: x[1])\n",
    "merged_temp2['death_ic_first'] = result.apply(lambda x: x[2])\n",
    "merged_temp2['ic_6hr_first'] = result.apply(lambda x: x[3])\n",
    "merged_temp2['acute_ic_first'] = result.apply(lambda x: x[4])\n",
    "merged_temp2['first_event'] = result.apply(lambda x: x[5])\n",
    "merged_temp2['is_first'] = result.apply(lambda x: x[6])\n",
    "\n",
    "merged_temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_temp2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_death_fullcode = (\n",
    "    merged_temp2[merged_temp2['death_fullcode'] & merged_temp2['ontslag_datum_tijd'].notna()]\n",
    "    .groupby('opname_id')['ontslag_datum_tijd']\n",
    "    .nunique()\n",
    ")\n",
    "merged_temp2['count_death_fullcode'] = merged_temp2['opname_id'].map(count_death_fullcode).fillna(0).astype(int)\n",
    "\n",
    "count_death_ic = (\n",
    "    merged_temp2[merged_temp2['death_ic'] & merged_temp2['ic_ontslag_datum_tijd'].notna()]\n",
    "    .groupby('opname_id')['ic_ontslag_datum_tijd']\n",
    "    .nunique()\n",
    ")\n",
    "merged_temp2['count_death_ic'] = merged_temp2['opname_id'].map(count_death_ic).fillna(0).astype(int)\n",
    "\n",
    "count_ic_6hr = (\n",
    "    merged_temp2[merged_temp2['ic_6hr'] & merged_temp2['ic_opname_datum_tijd'].notna()]\n",
    "    .groupby('opname_id')['ic_opname_datum_tijd']\n",
    "    .nunique()\n",
    ")\n",
    "merged_temp2['count_ic_6hr'] = merged_temp2['opname_id'].map(count_ic_6hr).fillna(0).astype(int)\n",
    "\n",
    "count_acute_ic = (\n",
    "    merged_temp2[merged_temp2['acute_ic'] & merged_temp2['ok_eind_datum_tijd'].notna() \n",
    "                 & merged_temp2['ic_opname_datum_tijd'].notna()]\n",
    "    .groupby('opname_id')['ok_eind_datum_tijd']\n",
    "    .nunique()\n",
    ")\n",
    "merged_temp2['count_acute_ic'] = merged_temp2['opname_id'].map(count_acute_ic).fillna(0).astype(int)\n",
    "\n",
    "print(merged_temp2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(merged_temp2['count_acute_ic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "max_count = merged_temp2['count_acute_ic'].max()\n",
    "merged_temp2[merged_temp2['count_acute_ic'] == max_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_temp2['first_event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate how to handle the negative values of time\n",
    "# 1) if the time period is > -(12hrs), then we see it as error, discard that (so -1 days +18:43:00 is NOT error)\n",
    "# 2) otherwise set to 0, (instead of without -12 hours, because we agreed to maximize the time)\n",
    "negative = merged_temp2['time_to_first_event'] < pd.Timedelta(0)\n",
    "negative = merged_temp2[negative]\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does it have late ok_begin_datum_tijd than opname datum tijd?\n",
    "opname1 = merged_temp2[merged_temp2['time_to_first_event'] == '-8 days +12:47:00']['opname_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opname1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo[copy_demo['opname_id'].isin(opname1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery[copy_surgery['opname_id'].isin(opname1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = merged_temp2['time_to_first_event'] < pd.Timedelta(hours=-12)\n",
    "merged_temp2 = merged_temp2.loc[~condition]\n",
    "\n",
    "negative = merged_temp2['time_to_first_event'] < pd.Timedelta(0)\n",
    "negative = merged_temp2[negative]\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_temp2[merged_temp2['time_to_first_event'] == '-8 days +12:47:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the time is between -12 hours to 0, then we consider this as 0\n",
    "condition = (merged_temp2['time_to_first_event'] >= pd.Timedelta(hours=-12)) & (merged_temp2['time_to_first_event'] < pd.Timedelta(hours=0))\n",
    "merged_temp2.loc[condition, 'time_to_first_event'] = pd.Timedelta(hours=0)\n",
    "merged_temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_temp2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo = pd.merge(copy_demo, merged_temp2, on=['p_id', 'opname_id'], how='left', suffixes=('', '_drop'))\n",
    "copy_demo = copy_demo[[c for c in copy_demo.columns if not c.endswith('_drop')]]\n",
    "copy_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for boolean column that contains NaN, fill in False\n",
    "boolean_col = copy_demo.select_dtypes(include=['bool', 'object']).columns\n",
    "copy_demo[boolean_col] = copy_demo[boolean_col].fillna(False)\n",
    "\n",
    "boolean_col = copy_demo.select_dtypes(include=['bool']).columns\n",
    "copy_demo[boolean_col] = copy_demo[boolean_col].astype('boolean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['first_event'] = copy_demo['first_event'].fillna(0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['time_to_first_event'] = copy_demo['time_to_first_event'].dt.total_seconds() / 60\n",
    "copy_demo['time_to_first_event'] = copy_demo['time_to_first_event'].astype('UInt32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "This is old code below. It's not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create deceased event\n",
    "# copy_demo['is_deceased'] = copy_demo['overlijdens_datum'].notna()\n",
    "# copy_demo[copy_demo['overlijdens_datum'].notna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create deceased event based on the period (discharge - admission)\n",
    "# # assume that as soon as a patient passes away, discharge happens at the same time, \n",
    "# # as overlijdens_datum does not have time\n",
    "# # also we only deal with patients who passed away \n",
    "\n",
    "# # do not consider calculating rows where ontslag_datum_tijd dates are eariler than overlijdens_datum\n",
    "# # because the focus is in death within hospital\n",
    "# # TODO: however, can we not use these patients for estimating deterioration on other stuff? (vital score)\n",
    "\n",
    "# deceased= copy_demo['is_deceased']\n",
    "# same_date = copy_demo['ontslag_datum_tijd'].dt.date == copy_demo['overlijdens_datum'].dt.date\n",
    "# copy_demo['is_deceased_hospital'] = deceased & same_date\n",
    "# copy_demo.loc[copy_demo['is_deceased_hospital'], 'survival_period_hospital'] = \\\n",
    "#     ((copy_demo['ontslag_datum_tijd'] - copy_demo['opname_datum_tijd']).dt.total_seconds() / 3600).round(1)\n",
    "\n",
    "# # based on deceased with 12 hours or 24 hours\n",
    "# copy_demo = copy_demo.assign(\n",
    "#     is_deceased_12h = deceased & same_date & (copy_demo['survival_period_hospital'] < 12),\n",
    "#     is_deceased_24h = deceased & same_date & (copy_demo['survival_period_hospital'] < 24)\n",
    "# )\n",
    "\n",
    "# copy_demo.loc[copy_demo['is_deceased_12h'], 'survival_period_hospital_12h'] = \\\n",
    "#     ((copy_demo['ontslag_datum_tijd'] - copy_demo['opname_datum_tijd']).dt.total_seconds() / 3600).round(1)\n",
    "\n",
    "# copy_demo.loc[copy_demo['is_deceased_24h'], 'survival_period_hospital_24h'] = \\\n",
    "#     ((copy_demo['ontslag_datum_tijd'] - copy_demo['opname_datum_tijd']).dt.total_seconds() / 3600).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_demo[copy_demo['survival_period_hospital_24h'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove case sensitivity again\n",
    "copy_vitals.columns = copy_vitals.columns.str.lower()\n",
    "copy_surgery.columns = copy_surgery.columns.str.lower()\n",
    "copy_reanimatie.columns = copy_reanimatie.columns.str.lower()\n",
    "copy_lab.columns = copy_lab.columns.str.lower()\n",
    "copy_ic.columns = copy_ic.columns.str.lower()\n",
    "copy_demo.columns = copy_demo.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert some datetime variables as duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # duration surgery\n",
    "# copy_surgery['duration_surgery'] = (\n",
    "#     copy_surgery['ok_eind_datum_tijd'] - copy_surgery['ok_begin_datum_tijd']).dt.total_seconds() / 60\n",
    "\n",
    "# copy_surgery = copy_surgery.drop(['ok_begin_datum_tijd', 'ok_eind_datum_tijd'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # duration ic\n",
    "# copy_ic['duration_ic'] = (\n",
    "#     copy_ic['ic_ontslag_datum_tijd'] - copy_ic['ic_opname_datum_tijd']).dt.total_seconds() / 60\n",
    "\n",
    "# copy_ic = copy_ic.drop(['ic_ontslag_datum_tijd', 'ic_opname_datum_tijd'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # duration hospital\n",
    "# copy_demo['duration_hospital'] = (\n",
    "#     copy_demo['ontslag_datum_tijd'] - copy_demo['opname_datum_tijd']).dt.total_seconds() / 60\n",
    "\n",
    "# copy_demo = copy_demo.drop(['opname_datum_tijd', 'ontslag_datum_tijd', 'care_order_full_code',\n",
    "#                             'ic_ontslag_datum_tijd', 'ic_opname_datum_tijd', 'ok_begin_datum_tijd', \n",
    "#                             'prioriteit_code_acute'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Converting for datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [copy_vitals, copy_surgery, copy_reanimatie, copy_lab, copy_ic, copy_demo]\n",
    "total_memory = 0\n",
    "\n",
    "for df in dataframes:\n",
    "    memory = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    total_memory += memory\n",
    "    \n",
    "print(f\"Total memory usage: {total_memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this function because if I read the parquet file in other jupyterfile, then datetime64 changes\n",
    "# # this should be used after rounding up time\n",
    "# # NOT USED, only parts of it\n",
    "# # defining more variables (season, time of day (morning))\n",
    "def get_year(year):\n",
    "    if 2018 <= year <= 2019:\n",
    "        return 'year1'\n",
    "    else:\n",
    "        return 'year2'\n",
    "\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'Spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'Summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "    \n",
    "def get_day(day):\n",
    "    if 1 <= day <= 10:\n",
    "        return 'day1'\n",
    "    elif 11 <= day <= 20:\n",
    "        return 'day2'\n",
    "    else:\n",
    "        return 'day3'\n",
    "    \n",
    "def get_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "    \n",
    "# this increases memory but we might need this, at least temporarily, for calculating periods\n",
    "# split datetime columns into separate columns such as year, day, hour, etc\n",
    "def split_datetime_to_numeric_cols(dataframes):\n",
    "\n",
    "    # iterate for each dataframe\n",
    "    for i in range(len(dataframes)):\n",
    "\n",
    "        # identify columns whose types are datetime64\n",
    "        df = dataframes[i]\n",
    "        datetime_cols = df.select_dtypes(include=['datetime64']).columns\n",
    "        \n",
    "        for datetime_col in datetime_cols:\n",
    "            \n",
    "#             # extracting attributes (I don't have to typecase here, but this is to compare memory)\n",
    "            df[datetime_col + '_year'] = df[datetime_col].dt.year.astype('UInt16')\n",
    "            df[datetime_col + '_month'] = df[datetime_col].dt.month.astype('UInt8')\n",
    "            df[datetime_col + '_day_of_month'] = df[datetime_col].dt.day.astype('UInt8')\n",
    "            df[datetime_col + '_hour'] = df[datetime_col].dt.hour.astype('UInt8')\n",
    "#             df[datetime_col + '_minute'] = df[datetime_col].dt.minute.astype('UInt8')\n",
    "#             df[datetime_col + '_second'] = df[datetime_col].dt.second.astype('UInt8')\n",
    "            \n",
    "#             # weekday/weekends, days of the week (monday)\n",
    "#             df[datetime_col + '_is_weekday'] = df[datetime_col].dt.weekday.isin(range(0, 5)).astype('boolean')\n",
    "#             df[datetime_col + '_day_of_week'] = df[datetime_col].dt.day_name()\n",
    "            \n",
    "            # get each datetime column for each datetime column\n",
    "#             df[datetime_col + '_year'] = df[datetime_col].dt.year.apply(get_year)\n",
    "#             df[datetime_col + '_season'] = df[datetime_col].dt.month.apply(get_season)\n",
    "#             df[datetime_col + '_day'] = df[datetime_col].dt.day.apply(get_day)\n",
    "#             df[datetime_col + '_time_of_day'] = df[datetime_col].dt.hour.apply(get_time_of_day)\n",
    "\n",
    "#             # one-hot encoding\n",
    "#             for category in ['year', 'season', 'day', 'time_of_day']:\n",
    "#                 cate_col = datetime_col + '_' + category\n",
    "#                 dummies = pd.get_dummies(df[cate_col], prefix=datetime_col, dtype='boolean')\n",
    "                \n",
    "#                 # drop the cate_col except for dummies\n",
    "#                 dummies.columns = [col.replace('_' + category + '_', '_') for col in dummies.columns]\n",
    "#                 df = pd.concat([df, dummies], axis=1)\n",
    "#                 df = df.drop(cate_col, axis=1)\n",
    "\n",
    "        dataframes[i] = df.reset_index(drop=True)\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = split_datetime_to_numeric_cols(dataframes)\n",
    "copy_vitals = dataframes[0]\n",
    "copy_surgery = dataframes[1]\n",
    "copy_reanimatie = dataframes[2]\n",
    "copy_lab = dataframes[3]\n",
    "copy_ic = dataframes[4]\n",
    "copy_demo = dataframes[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def meting_bool(df, col=\"meting_datum_tijd\"):\n",
    "#     df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "#     # extract\n",
    "#     df['year'] = df[col].dt.year\n",
    "#     df['month'] = df[col].dt.month\n",
    "#     df['day'] = df[col].dt.day\n",
    "#     df['hour'] = df[col].dt.hour\n",
    "    \n",
    "#     # year\n",
    "#     df['is_year1'] = (df['year'] >= 2018) & (df['year'] <= 2019)\n",
    "#     df['is_year2'] = ~df['is_year1']\n",
    "    \n",
    "#     # seasons\n",
    "#     df['is_spring'] = df['month'].isin([3, 4, 5])\n",
    "#     df['is_summer'] = df['month'].isin([6, 7, 8])\n",
    "#     df['is_autumn'] = df['month'].isin([9, 10, 11])\n",
    "#     df['is_winter'] = df['month'].isin([12, 1, 2])\n",
    "    \n",
    "#     # day\n",
    "#     df['is_day1'] = (df['day'] >= 1) & (df['day'] <= 10)\n",
    "#     df['is_day2'] = (df['day'] >= 11) & (df['day'] <= 20)\n",
    "#     df['is_day3'] = df['day'] >= 21\n",
    "    \n",
    "#     # time of day\n",
    "#     df['is_morning'] = (df['hour'] >= 5) & (df['hour'] < 12)\n",
    "#     df['is_afternoon'] = (df['hour'] >= 12) & (df['hour'] < 17)\n",
    "#     df['is_evening'] = (df['hour'] >= 17) & (df['hour'] < 21)\n",
    "#     df['is_night'] = ~(df['is_morning'] | df['is_afternoon'] | df['is_evening'])\n",
    "\n",
    "#     df.drop(columns=['year', 'month', 'day', 'hour'], inplace=True)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# meting_bool(copy_vitals, col=\"meting_datum_tijd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meting_int(df, col=\"meting_datum_tijd\"):\n",
    "\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    df['m_year'] = df[col].dt.year\n",
    "    df['m_month'] = df[col].dt.month\n",
    "    df['m_day'] = df[col].dt.day\n",
    "    df['m_hour'] = df[col].dt.hour\n",
    "    \n",
    "    df = df[['m_year', 'm_month', 'm_day', 'm_hour']].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "meting_int(copy_vitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [copy_vitals, copy_surgery, copy_reanimatie, copy_lab, copy_ic, copy_demo]\n",
    "total_memory = 0\n",
    "\n",
    "for df in dataframes:\n",
    "    memory = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    total_memory += memory\n",
    "    \n",
    "print(f\"Total memory usage: {total_memory} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OLD CODE for NEWS2 (NOT NEEDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate the total NEWS2 score based on vital measurements\n",
    "# # Not needed \n",
    "# def calculate_news2(vitals):\n",
    "    \n",
    "#     # resp\n",
    "#     if 'resp_meet_waarde1' in vitals.columns:\n",
    "#         vitals['resp_score'] = 0\n",
    "#         vitals.loc[vitals['resp_meet_waarde1'] <= 8, 'resp_score'] = 3\n",
    "#         vitals.loc[vitals['resp_meet_waarde1'].between(9, 11), 'resp_score'] = 1\n",
    "#         vitals.loc[vitals['resp_meet_waarde1'].between(21, 24), 'resp_score'] = 2\n",
    "#         vitals.loc[vitals['resp_meet_waarde1'] >= 25, 'resp_score'] = 3\n",
    "    \n",
    "#     # o2\n",
    "#     if 'o2_meet_waarde1' in vitals.columns:\n",
    "#         vitals['o2_score'] = 0\n",
    "#         vitals.loc[vitals['o2_meet_waarde1'] <= 91, 'o2_score'] = 3\n",
    "#         vitals.loc[vitals['o2_meet_waarde1'].between(92, 93), 'o2_score'] = 2\n",
    "#         vitals.loc[vitals['o2_meet_waarde1'].between(94, 95), 'o2_score'] = 1\n",
    "    \n",
    "#     # temperature\n",
    "#     if 'temp_meet_waarde1' in vitals.columns:\n",
    "#         vitals['temp_score'] = 0\n",
    "#         vitals.loc[vitals['temp_meet_waarde1'] <= 35, 'temp_score'] = 3\n",
    "#         vitals.loc[vitals['temp_meet_waarde1'].between(35.1, 36), 'temp_score'] = 1\n",
    "#         vitals.loc[vitals['temp_meet_waarde1'].between(38.1, 39), 'temp_score'] = 1\n",
    "#         vitals.loc[vitals['temp_meet_waarde1'] >= 39.1, 'temp_score'] = 2\n",
    "    \n",
    "#     # systolic blood pressure (nibp_meet_waarde1)\n",
    "#     if 'nibp_meet_waarde1' in vitals.columns:\n",
    "#         vitals['nibp1_score'] = 0\n",
    "#         vitals.loc[vitals['nibp_meet_waarde1'] <= 90, 'nibp1_score'] = 3\n",
    "#         vitals.loc[vitals['nibp_meet_waarde1'].between(91, 100), 'nibp1_score'] = 2\n",
    "#         vitals.loc[vitals['nibp_meet_waarde1'].between(101, 110), 'nibp1_score'] = 1\n",
    "#         vitals.loc[vitals['nibp_meet_waarde1'] >= 220, 'nibp1_score'] = 3\n",
    "    \n",
    "#     # heart rate\n",
    "#     if 'hr_meet_waarde1' in vitals.columns:\n",
    "#         vitals['hr_score'] = 0\n",
    "#         vitals.loc[vitals['hr_meet_waarde1'] <= 40, 'hr_score'] = 3\n",
    "#         vitals.loc[vitals['hr_meet_waarde1'].between(41, 50), 'hr_score'] = 1\n",
    "#         vitals.loc[vitals['hr_meet_waarde1'].between(91, 110), 'hr_score'] = 1\n",
    "#         vitals.loc[vitals['hr_meet_waarde1'].between(111, 130), 'hr_score'] = 2\n",
    "#         vitals.loc[vitals['hr_meet_waarde1'] >= 131, 'hr_score'] = 3\n",
    "        \n",
    "#     # spo2\n",
    "#     if 'spo2_meet_waarde1' in vitals.columns:\n",
    "#         vitals['spo2_score'] = 0\n",
    "#         vitals.loc[vitals['spo2_meet_waarde1'] != 0, 'spo2_score'] = 2\n",
    "    \n",
    "#     # calculate the total NEWS2 score\n",
    "#     cols = ['resp_score', 'o2_score', 'temp_score', 'nibp1_score', 'hr_score', 'avpu_score', 'spo2_score']\n",
    "#     score = [col for col in cols if col in vitals.columns]\n",
    "#     vitals['news2_score'] = vitals[score].sum(axis=1)\n",
    "    \n",
    "#     return vitals\n",
    "\n",
    "# calculate_news2(copy_vitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = calculate_news2(copy_vitals)\n",
    "# f['news2_score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://www.nice.org.uk/advice/mib205/chapter/The-technology#:~:text=Medium%20risk%20(aggregate%20score%205,to%20higher%2Ddependency%20care%20area.\n",
    "\n",
    "Low risk (aggregate score 1 to 4) – prompt assessment by ward nurse to decide on change to frequency of monitoring or escalation of clinical care.\n",
    "\n",
    "Medium risk (aggregate score 5 to 6) – urgent review by ward-based doctor or acute team nurse to decide on escalation to critical care team.\n",
    "\n",
    "High risk (aggregate score of 7 or over) – emergency assessment by critical care team, usually leading to patient transfer to higher-dependency care area.\n",
    "\n",
    "So deterioration: Low risk -> Medium risk, Medium risk -> High risk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals['news2_low_risk'] = copy_vitals['news2_score'].between(1, 4, inclusive='both')\n",
    "# copy_vitals['news2_medium_risk'] = copy_vitals['news2_score'].between(5, 6, inclusive='both')\n",
    "# copy_vitals['news2_high_risk'] = copy_vitals['news2_score'] >= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals = copy_vitals.sort_values(['p_id', 'opname_id', 'meting_datum_tijd']).reset_index(drop=True)\n",
    "\n",
    "# grouped = copy_vitals.groupby(['p_id', 'opname_id'])\n",
    "\n",
    "# copy_vitals['prev_low_risk'] = grouped['news2_low_risk'].shift(1)\n",
    "# copy_vitals['prev_medium_risk'] = grouped['news2_medium_risk'].shift(1)\n",
    "# copy_vitals['prev_meting_datum_tijd'] = grouped['meting_datum_tijd'].shift(1)\n",
    "\n",
    "# copy_vitals['time_diff_hours'] = (\n",
    "#     copy_vitals['meting_datum_tijd'] - copy_vitals['prev_meting_datum_tijd']\n",
    "# ).dt.total_seconds() / 3600\n",
    "\n",
    "# copy_vitals['is_vital_worse_12h'] = (\n",
    "#     (copy_vitals['time_diff_hours'] <= 12) &\n",
    "#     ((copy_vitals['prev_low_risk'] & copy_vitals['news2_medium_risk']) |\n",
    "#         (copy_vitals['prev_medium_risk'] & copy_vitals['news2_high_risk'])))\n",
    "\n",
    "# copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals[(copy_vitals['is_vital_worse_12h']==True) & (copy_vitals['news2_high_risk']==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# op1 = copy_vitals[(copy_vitals['is_vital_worse_12h']==True) & (copy_vitals['news2_high_risk']==True)].iloc[0]['opname_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals[copy_vitals['opname_id']==op1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Converting data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To efficiently manage the memory size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which cols don't have NaN values (float)\n",
    "copy_lab.columns[copy_lab.notna().all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vitals: test how many decimal digits each type can handle\n",
    "# decimal places up to 1 (nums after point)\n",
    "o = 4.59\n",
    "o = round(o, 1)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)\n",
    "\n",
    "o = 45.59\n",
    "o = round(o, 1)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "# if the interger part is > 2, float32 better\n",
    "print(o_float32)\n",
    "print(o_float_n)\n",
    "\n",
    "o = 455.59\n",
    "o = round(o, 1)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab: test how many decimal digits each type can handle\n",
    "# decimal places up to 2 (nums after point)\n",
    "o = -1.188\n",
    "o = round(o, 2)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)\n",
    "\n",
    "o = 1.188\n",
    "o = round(o, 2)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)\n",
    "\n",
    "o = 11.188\n",
    "o = round(o, 2)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)\n",
    "\n",
    "# if the interger part is > 2, float32 better\n",
    "o = 111.188\n",
    "o = round(o, 2)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)\n",
    "\n",
    "o = 1111.188\n",
    "o = round(o, 2)\n",
    "o_float32 = np.float32(o)\n",
    "o_float_n = o_float32.astype('float16')\n",
    "\n",
    "print(o_float32)\n",
    "print(o_float_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float precision\n",
    "precision_float16 = np.finfo(np.float16).precision\n",
    "precision_float32 = np.finfo(np.float32).precision\n",
    "precision_float64 = np.finfo(np.float64).precision\n",
    "precision_float128 = np.finfo(np.float128).precision\n",
    "\n",
    "print(precision_float16)\n",
    "print(precision_float32)\n",
    "print(precision_float64)\n",
    "print(precision_float128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(copy_vitals.min())\n",
    "print(copy_vitals.max())\n",
    "print(copy_lab.min())\n",
    "print(copy_lab.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals['nibp_meet_waarde3'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtypes(df, decimal_places=None):\n",
    "\n",
    "    # loop through each column\n",
    "    for col in df.columns:\n",
    "        \n",
    "        # if the datatype is numeric\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            \n",
    "            # get min and max values\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "            \n",
    "            # if the datatype is float\n",
    "            # this doesn't check whether the content is indeed float or not\n",
    "            # it only checks explicit datatype            \n",
    "            if pd.api.types.is_float_dtype(df[col]):\n",
    "                \n",
    "                # only round if decimal_places is provided\n",
    "                if decimal_places is not None:\n",
    "                    \n",
    "                    # round the column to the specified decimal places\n",
    "                    df[col] = df[col].round(decimal_places)\n",
    "                \n",
    "                # get integer part of maximum absolute value\n",
    "                # we don't use col_min for calculating max digits, because min is -1.0 anyway\n",
    "                integer_part = int(abs(col_max))\n",
    "                \n",
    "                # count number of digits in integer part\n",
    "                int_digits = len(str(integer_part))\n",
    "                \n",
    "                # decide whether to convert to float16 or float32\n",
    "                # float16 doesn't work depends on the machine\n",
    "#                 if int_digits < 3:\n",
    "#                     df[col] = df[col].astype(np.float16)\n",
    "#                 else:\n",
    "#                     df[col] = df[col].astype(np.float32)\n",
    "\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "                    \n",
    "            # otherwise if the datatype is integer\n",
    "            elif pd.api.types.is_integer_dtype(df[col]):\n",
    "                \n",
    "                # if the minimum is smaller than 0, set signed integer\n",
    "                if col_min < 0:\n",
    "                    \n",
    "                    # assign nullable type Int8 or Int16 depends on the range\n",
    "                    if col_min >= np.iinfo(np.int8).min and col_max <= np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype('Int8')\n",
    "                    elif col_min >= np.iinfo(np.int16).min and col_max <= np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype('Int16')\n",
    "                \n",
    "                # if the minimum is NOT smaller than 0, set unsigned integer\n",
    "                else:\n",
    "                    \n",
    "                    # assign nullable type UInt8 or UInt16 depends on the range\n",
    "                    if col_max <= np.iinfo(np.uint8).max:\n",
    "                        df[col] = df[col].astype('UInt8')\n",
    "                    elif col_max <= np.iinfo(np.uint16).max:\n",
    "                        df[col] = df[col].astype('UInt16')\n",
    "\n",
    "    # return the converted dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types into all dataframes\n",
    "copy_vitals = convert_dtypes(copy_vitals, decimal_places = 1)\n",
    "copy_surgery = convert_dtypes(copy_surgery)\n",
    "copy_reanimatie = convert_dtypes(copy_reanimatie)\n",
    "copy_lab = convert_dtypes(copy_lab, decimal_places = 2)\n",
    "copy_ic = convert_dtypes(copy_ic)\n",
    "copy_demo = convert_dtypes(copy_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can see the data is rounded up to 1 decimal place\n",
    "copy_vitals['nibp_meet_waarde3'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [copy_vitals, copy_surgery, copy_reanimatie, copy_lab, copy_ic, copy_demo]\n",
    "\n",
    "total_memory = 0\n",
    "\n",
    "for df in dataframes:\n",
    "    memory = df.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    total_memory += memory\n",
    "    \n",
    "print(f\"Total memory usage: {total_memory} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is only for the display purposes, doesn't affect actual data\n",
    "# 3 because if i do 2, then it may round up to the display over already rounded data\n",
    "# the dataframe number is binary so it may look different than actual data though\n",
    "pd.set_option('display.precision', 3)\n",
    "copy_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals['nibp_meet_waarde3'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extra Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in lab, remove symbols\n",
    "copy_lab.columns = (copy_lab.columns\n",
    "                    .str.replace(r'[\\(\\)]', '', regex=True)\n",
    "                    .str.replace('-', '_'))\n",
    "copy_lab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_surgery.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_reanimatie.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_lab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_vitals = copy_vitals.drop('meting_datum_tijd', axis=1)\n",
    "\n",
    "# # because it's 0 now\n",
    "# copy_vitals = copy_vitals.drop('meting_datum_tijd_minute', axis=1)\n",
    "\n",
    "# copy_reanimatie = copy_reanimatie.drop('vanaf_datum', axis=1)\n",
    "\n",
    "# copy_lab = copy_lab.drop('lab_datum_tijd', axis=1)\n",
    "\n",
    "# copy_ic = copy_ic.drop('ic_6hr', axis=1)\n",
    "\n",
    "# copy_demo = copy_demo.drop(['overlijdens_datum', 'overlijdens_datum_hour', 'overlijdens_datum_minute'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = ['count_death_fullcode', 'count_death_ic', 'count_ic_6hr', 'count_acute_ic']\n",
    "copy_demo[count_cols] = copy_demo[count_cols].fillna(0)\n",
    "copy_demo[count_cols] = copy_demo[count_cols].astype('UInt8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save dataframes to parquet   \n",
    "Saving to parquet messes the datetime64 somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [copy_vitals, copy_surgery, copy_reanimatie, copy_lab, copy_ic, copy_demo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize titles\n",
    "titles = [\"vitals\", \"surgery\", \"reanimatie\", \"lab\", \"ic_opnames\", \"demographics\"]\n",
    "\n",
    "# specify the output directory for saving parquet files\n",
    "output_dir = '..'\n",
    "\n",
    "# create the folder if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# save each dataframe as a parquet file\n",
    "for df, title in zip(dataframes, titles):\n",
    "    output_path = os.path.join(output_dir, f\"{title}.parquet\")\n",
    "\n",
    "    # check if the file already exists\n",
    "    if not os.path.isfile(output_path):\n",
    "        try:\n",
    "            # save dataframe to parquet file\n",
    "            df.to_parquet(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save {title}: {e}.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_parquet(output_dir + '/vitals.parquet')\n",
    "v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['nibp_meet_waarde3'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_vitals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['opname_datum_tijd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_demo['opname_datum_tijd'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "fce4fb90388deaf1bd48d5cd0085ba64bba4d4518b6644dfe47737140f7fef1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
